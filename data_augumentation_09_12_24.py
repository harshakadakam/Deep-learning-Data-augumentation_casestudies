# -*- coding: utf-8 -*-
"""Data_Augumentation_09_12_24

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qwK-t_cQcSw4Lsmb-gkIOAsJhou0_EK-

# Step:01-Import libraries
"""

import numpy as np
 import matplotlib.pyplot as plt
 import pandas as pd
 import seaborn as sns
 import tensorflow as tf
 from tensorflow import keras
 import tensorflow_datasets as tfds
 from keras import layers
 from keras.layers import Dense, Dropout
 from keras.models import Sequential
 import warnings
 warnings.filterwarnings('ignore')

"""# Step:02-Loading_data"""

tfds.list_builders()

(train_data, val_data, test_data),matadata = tfds.load(
    'tf_flowers',
    split=('train[:80%]', 'train[80%:90%]', 'train[90%:]'),
    with_info=True,
    as_supervised=True,
 )

type(train_data)

train_data.take(1)

"""View Data"""

image,label = next(iter(train_data.take(5)))
plt.imshow(image)
label_name=matadata.features['label'].int2str(label)
#plt.title(str(label.numpy()))
plt.title(label_name)

image, label = next(iter(train_data))
plt.imshow(image)
label_name = matadata.features['label'].int2str(label)
#plt.title(str(label.numpy()))
plt.title(label_name)

images = []
labels = []
for image, label in iter(train_data.take(3)):
  print(image.shape)
  print(label)
  label_name = matadata.features['label'].int2str(label)
  print(label_name)
  images.append(image)
  labels.append(label_name)

fig,ax = plt.subplots(1,3,figsize=(20,20))
for i in range(3):
    ax[i].imshow(images[i])
    ax[i].set_title(labels[i])
plt.show()

"""# Step - Basic Preprocessing

"""

#(333, 500, 3) - Height:333, Width:500, 3-> Color Image
IMG_SIZE = 180
resize_rescale = tf.keras.Sequential([
    layers.Resizing(IMG_SIZE,IMG_SIZE), # Resize - 180,180,3
    layers.Rescaling(1./255) # Normalization --> 0-255 --> 0-1
])

result = resize_rescale(images[0])
plt.imshow(result)

"""# Step4: Data Augmentation"""

data_augmentation = tf.keras.Sequential([
    layers.RandomFlip('horizontal_and_vertical'),
    layers.RandomRotation(0.2),
    layers.RandomZoom(0.2),
    layers.RandomContrast(0.2)
])

images[0]

processing =tf.keras.Sequential([
    resize_rescale,
    data_augmentation
 ])
 processing

r = processing(images[0])
plt.imshow(r)

"""# Build The model"""

IMG_SIZE = 128
num_classes = 5
model =tf.keras.Sequential([
    tf.keras.layers.InputLayer(input_shape=(IMG_SIZE, IMG_SIZE, 3)),
    tf.keras.layers.Conv2D(32, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(32, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(32, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(num_classes, activation='softmax')
])

model.summary()

"""# Step 7: Preprocessing Data


"""

def preprocess(image, label):
    image = resize_rescale(image)
    image = data_augmentation(image)
    return image, label

train_data = train_data.map(preprocess).cache().batch(32).prefetch(tf.data.AUTOTUNE)
val_data = val_data.map(preprocess).cache().batch(32).prefetch(tf.data.AUTOTUNE)
test_data = test_data.map(preprocess).cache().batch(32).prefetch(tf.data.AUTOTUNE)

"""# Training the Model"""

IMG_SIZE = 128
def preprocess(image, label):
    image = resize_rescale(image)
    image = data_augmentation(image)
    return image, label
model =tf.keras.Sequential([
    tf.keras.layers.InputLayer(input_shape=(IMG_SIZE, IMG_SIZE, 3)),
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

"""# Evaluating the model"""

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.summary()
accuracy, loss = model.evaluate(test_data)
print(f"Test Accuracy: {accuracy}, Test Loss: {loss}")